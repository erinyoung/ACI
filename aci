#!/usr/bin/env python3

'''
Author: Erin Young

Description:

This script will find the coverage for each amplicon in a bedfile and then graph it.

Tis masqurading as a real python program.

EXAMPLE:
aci -b input.bam -d amplicon.bed -o out
'''

# I tried to keep dependencies down...
import argparse
import concurrent.futures
import itertools
import logging
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import pysam
import subprocess
import sys

# about 30 seconds per artic V3 primer on SRR13957125
# $ samtools coverage SRR13957125.sorted.bam
# #rname      startpos endpos numreads covbases coverage meandepth meanbaseq meanmapq
# MN908947.3  1        29903  1141595  29827    99.7458  5350.27   37.3      60
# 15000 - 16500

version = '0.0.20230815'
logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%y-%b-%d %H:%M:%S', level=logging.INFO)

parser  = argparse.ArgumentParser()
parser.add_argument('-b', '--bam', nargs = '+', required= True, type=str, help='(required) input bam file')
parser.add_argument('-d', '--bed', required = True, type = str, help ='(required) amplicon bedfile')
parser.add_argument('-s', '--single', action='store_true', help ='flag that specifies that reads are single-end in bam file')
parser.add_argument('-o', '--out', type=str, help='directory for results', default='aci')
parser.add_argument('-t', '--threads', type=int, help='specifies number of threads to use', default=4)
parser.add_argument('-v', '--version', help='print version and exit', action='version', version='%(prog)s ' + version)
args    = parser.parse_args()

# the function that reduces the bam file to the region in question and then gets coverage
def amplicon_depth(df, bam, region, single):
    logging.debug('Made it to checkpoint 0 for ' + bam)
    ref        = region.split(':')[0]
    start      = int(region.split(':')[1])
    end        = int(region.split(':')[2])
    name       = region.split(':')[3]
    subregion  = ref + ':' + str(start) + '-' + str(end)
    file_name  = os.path.basename(bam)

    bed1 = args.out + '/tmp.' + name + '.'   + file_name + '.bed'
    bam0 = args.out + '/tmp.' + name + '.0.' + file_name
    bam1 = args.out + '/tmp.' + name + '.1.' + file_name
    bam2 = args.out + '/tmp.' + name + '.2.' + file_name
    bam3 = args.out + '/tmp.' + name + '.3.' + file_name
    bam4 = args.out + '/tmp.' + name + '.4.' + file_name
    logging.debug('temp filenames are ' + bed1 + ', ' + bam0 + ', ' + bam1 + ', ' + bam2 + ', ' + bam3 + ', and ' + bam4 )

    if start <= 1:
        with open(bed1, mode='wt') as file:
            file.write(ref + '\t' + str(end + 1) + '\t5000000\n')
    else:
        with open(bed1, mode='wt') as file:
            file.write(ref + '\t' + str('0') + '\t' + str(start - 1) + '\n' + ref + '\t' + str(end + 1) + '\t5000000\n')

    # running samtools via pysam
    if os.path.exists(bam):
        pysam.sort('-o', bam0, bam)
        logging.debug('Made it to checkpoint 1 for ' + bam)
   
    if os.path.exists(bam0):
        pysam.index(bam0)

        logging.debug('Made it to checkpoint 2 for ' + bam)
        single_check = int(pysam.view('-c', '-f',  '1', bam0))
        if single_check == 0 and not single :
            single = True
            logging.warning(bam + ' is single end')

        logging.debug('Made it to checkpoint 3 for ' + bam)
        if single:
            pysam.view('-bh', '-o', bam1, bam0, subregion, catch_stdout=False)    
        else:
            pysam.view('-bh','-f2', '-o', bam1, bam0, subregion, catch_stdout=False)
        os.remove(bam0)
        os.remove(bam0 + '.bai')
    
    logging.debug('Made it to checkpoint 4 for ' + bam)
    if os.path.exists(bam1):
        pysam.index(bam1)
        pysam.view('-bh', bam1, '-U', bam2, '-o', bam3, '-L', bed1, catch_stdout=False)
        os.remove(bam1)
        os.remove(bam1 + '.bai')
    
    logging.debug('Made it to checkpoint 5 for ' + bam)
    os.remove(bed1)

    logging.debug('Made it to checkpoint 6 for ' + bam)
    if os.path.exists(bam2):
        pysam.index(bam2)
        if single:
            pysam.view('-bh', '-o', bam4, bam2, subregion, catch_stdout=False)    
        else:
            pysam.view('-bh', '-f2', '-o', bam4, bam2, subregion, catch_stdout=False)
        os.remove(bam2)
        os.remove(bam2 + '.bai')
        os.remove(bam3)

    logging.debug('Made it to checkpoint 7 for ' + bam)    
    if os.path.exists(bam4):
        pysam.index(bam4)
        cov=float(pysam.coverage('--no-header', bam4, '-r', subregion).split()[6]) 
        os.remove(bam4)
        os.remove(bam4 + '.bai')  
    else:
        cov=0

    logging.debug('Made it to checkpoint 8 for ' + bam)
    bamindex = df.index[df['bam'] == bam]
    df.loc[bamindex, [name]] = cov

if not os.path.exists(args.bed):
    logging.critical('bedfile ' + args.bed + ' does not exist. Exiting')
    exit(1)

if not os.path.exists(args.out):
    os.mkdir(args.out)

logging.info('ACI version :\t\t'     + str(version))
logging.info('Number of threads :\t' + str(args.threads))
logging.info('Final directory :\t\t' + str(args.out))
if args.single:
    logging.info('Read type :\t\tSingle')
else:
    logging.info('Read type :\t\tPaired')
logging.info('Input bed file :\t\t'    + str(args.bed))
logging.info('Input bam file(s) :\t' + ', '.join(args.bam))

##### ----- ----- ----- ----- ----- #####
##### Part 1. Amplicon depths       #####
##### ----- ----- ----- ----- ----- #####

logging.info('Getting depth for amplicons')
pool      = concurrent.futures.ThreadPoolExecutor(max_workers=args.threads)
df        = pd.DataFrame([])
df['bam'] = args.bam
regions   = []

with open(args.bed) as file:
    for line in file:
        ref=str(line.split('\t')[0])
        start=str(int(line.split('\t')[1]))
        end=str(int(line.split('\t')[2]))
        name=str(line.split('\t')[3])
        regions.append(ref + ':' + start + ':' + end + ':' + name)

for input in list(itertools.product(args.bam,regions)):
        if (args.single):
            pool.submit(amplicon_depth, df, input[0], input[1], True)
            logging.debug('Single bam file: ' + input[0])
            logging.debug('Region: ' + input[1])
            # amplicon_depth(df,input[0],input[1],True)
        else:
            pool.submit(amplicon_depth, df, input[0], input[1], False)
            # amplicon_depth(df,input[0],input[1],False)
            logging.debug('Paired bam file: ' + input[0])
            logging.debug('Region: ' + input[1])

pool.shutdown(wait=True)
logging.debug('Finished pooled function')

# writing results to a file
df.to_csv(args.out + '/amplicon_depth.csv', index=False)

# getting rid of column with all the bam names
df.drop('bam', axis=1, inplace=True)

boxplot = df.boxplot(fontsize=5, rot=90, figsize=(15,8), grid=False)
boxplot.plot()
plt.title('Primer Assessment')
boxplot.set_ylabel('meandepth')
boxplot.set_xlabel('amplicon name')
boxplot.figure.savefig(args.out + '/amplicon_depth.png', bbox_inches='tight')
plt.close()

logging.info('Depth for amplicons is saved in '  + args.out + '/amplicon_depth.csv')
logging.info('An boxplot of these depths is at ' + args.out + '/amplicon_depth.png')

# ##### ----- ----- ----- ----- ----- #####
# ##### Part 2. Genome/bam depths     #####
# ##### ----- ----- ----- ----- ----- #####
# def genome_depth(df1, bam):
#     file_name = os.path.basename(bam)

#     df2 = pd.DataFrame([x.split('\t') for x in pysam.depth(bam).split('\n')])
#     df2.columns = ['ref', 'pos', 'cov']

#     df3 = pd.DataFrame(columns = ['bam'] + df2['pos'].to_list())
#     df3.loc[1] = [bam] + df2['cov'].to_list()

#     df1 = pd.merge(df1, df3, how = 'outer')
#     print('df3')
#     print(df3)
#     print('df1')
#     print(df1)

# # now getting depth information for comparison
# df1        = pd.DataFrame([])
# df1['bam'] = args.bam

# for bam in args.bam:
#     genome_depth(df1, bam)

# print('Out of the function')
# print(df1)
# exit()

# # dividing positions into group for boxplot
# df1['group'] = (df1['pos'] / 500).apply(np.floor)
# df1 = df1.drop(['ref', 'pos'], axis=1)

# # getting a df for graphing
# df2 = df1.groupby(['group']).mean().reset_index()
# df2['start'] = (df2['group'] * 500).astype(int)
# df2['end']   = (df2['group'] * 500 + 499).astype(int)
# df2['pos']   = df2['start'].astype('str') + '-' + df2['end'].astype('str')

# # remove depth file
# os.remove(args.out + '/depth.txt')

# # writing results to a file
# df2.to_csv(args.out + '/genome_depth.csv', index=False)

# groups=df2['pos'].to_list()

# # getting rid of column with all the group names
# df2 = df2.drop(['group', 'pos', 'start','end'], axis=1)

# # switching columns (bam files) for rows (positions)
# df2 = df2.transpose()
# df2.columns=groups

# # creating the boxplot
# boxplot2 = df2.boxplot(fontsize=5, rot=90, figsize=(15,8), grid=False)
# boxplot2.plot()
# plt.title('Average depth across genome')
# boxplot2.set_ylabel('meandepth')
# boxplot2.set_xlabel('position (start-end)')
# boxplot2.figure.savefig(args.out + '/genome_depth.png', bbox_inches='tight')
# plt.close()

# print('Depth for the genome from the bam file is saved in ' + args.out + '/genome_depth.csv')
# print('An boxplot of these depths is at ' + args.out + '/genome_depth.png')

logging.info('ACI is complete! (And I hope all your primers are behaving as expected!)')
